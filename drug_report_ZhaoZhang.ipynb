{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> DATA CAMP REPORT </h2>\n",
    "by Zhao ZHANG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Introduction </h2>\n",
    "\n",
    "\n",
    "<p>The goal of this project is to develop prediction models able to <b>identify and quantify chemotherapeutic agents from their Raman spectra</b>.  \n",
    "\n",
    "\n",
    "Part of these data are saved in the file <code>train.csv</code> as follows (<code>n_samples</code> being the number of samples): \n",
    "<ul>\n",
    "    <li><b>molecule</b>: Type of chemotherapeutic agent. Six possible values: A for infliximab, B for b√©vacizumab, Q for ramucirumab, R for rituximab. Dimension: (<code>n_samples</code>,)</li>\n",
    "    <li><b>vial</b>: Vial type. Three possible values: 1, 2, 3. Dimension: (<code>1</code>, <code>n_samples</code>)</li>\n",
    "    <li><b>solute</b>: Solute group. Fourteen possible values: 1, 2, ..., 14. Dimension: (<code>1</code>, <code>n_samples</code>)</li>\n",
    "    <li><b>concentration</b>: Concentration of the molecule. Dimension: (<code>n_samples</code>, <code>1</code>)</li>\n",
    "    <li><b>spectra</b>: Intensity of Raman spectrum. Dimension: (<code>n_samples</code>, <code>1866</code>)</li>\n",
    "</ul>\n",
    "\n",
    "<p>To sum up, there are two objectives:\n",
    "\n",
    "<ul>\n",
    "    <li><b>classification</b>: predict which molecule it corresponds to given the spectrum.</li>\n",
    "    <li><b>regression</b>: predict the concentration of a molecule. The prediction should not depend on the vial or the solute group. The error metric is the mean absolute relative error (mare): $$\\frac{1}{n_{samples}}\\sum_{i=1}^{n_{samples}}\\left|\\frac{y_i-\\hat{y}_i}{y_i}\\right|$$ with $y$ and $\\hat{y}$ being the true and predicted concentration.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "data = pd.read_csv('train.csv')\n",
    "y_df = data[['molecule', 'concentration']]\n",
    "X_df = data.drop(['molecule', 'concentration'], axis=1)\n",
    "spectra = X_df['spectra'].values                                        \n",
    "spectra = np.array([np.array(dd[1:-1].split(',')).astype(float) for dd in spectra])    \n",
    "X_df['spectra'] = spectra.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   solute                                            spectra  vial\n",
      "0      11  [0.0152963, 0.0152944, 0.0153142, 0.0154096, 0...     1\n",
      "1       1  [0.0143634, 0.0143292, 0.0143999, 0.0145162, 0...     1\n",
      "2       3  [0.0163027, 0.0161848, 0.0163573, 0.0164119, 0...     1\n",
      "3      10  [0.0135833, 0.0135537, 0.0134438, 0.0136424, 0...     2\n",
      "4       2  [0.020811, 0.020767, 0.0208674, 0.0207018, 0.0...     3\n",
      "5       4  [0.0273853, 0.0271442, 0.0273076, 0.0272756, 0...     1\n",
      "6       5  [0.016065, 0.0161625, 0.0161815, 0.0162885, 0....     3\n",
      "7       9  [0.0225653, 0.0226097, 0.0222985, 0.0224744, 0...     2\n",
      "8       1  [0.0145261, 0.014045, 0.0144388, 0.0143233, 0....     3\n",
      "9       1  [0.0139963, 0.0143121, 0.0143192, 0.0140011, 0...     3\n"
     ]
    }
   ],
   "source": [
    "print X_df.head(1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 999\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATYAAAElCAYAAABu/s6cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x+rd6lpMm8vsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd9b10a4ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Types of molecules\n",
    "np.unique(y_df['molecule'].values)\n",
    "print('Number of samples: %s' % len(y_df))\n",
    "y_df.groupby('molecule').count().plot(y='concentration', kind='pie', autopct='%.2f', figsize=(5, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part, I just added a function of preprocessing. For some classifications, the normalization of data should be necessary and it also make some progress. I tried several methods, but it returned worse result, such as Kbest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "class FeatureExtractorClf():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        # Normalise the data\n",
    "        XX = np.array([np.array(dd) for dd in X_df['spectra']])\n",
    "        XX = preprocessing.normalize(XX)\n",
    "        return XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification: predicting the molecule type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my code, every model should added a function PCA. Because 1866 features are too many for only 999 sample, so after PCA, it will reture n_components most important features. It really improves the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I added a function XGBClassifier following the RandomForestClassifier, because the RandomForestClassifier contains a function of transforma. So, after the feature selection by PCA, the RandomForestClassifier transforms the selected features and it will be the input of the XGBClassifier. It did decease the error rate(from 0.1 to 0.08). But I found that most of Classifier are not runable as this form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, I added several classifiers (ExtraTreesClassifier, SVM, KNN,XGBClassifier)\n",
    "and I tried to merge these 4 classifiers. In my second submission, I gave weight to every prediction just like voting. And it got a better result(0.043 error rate). In fact, I spended so much time for calculating the weights for voting, but actually, after cross-validation, it means nothing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thirdly, because I spended so long time to modify the weights and the parameters and it didn't work, I tried to find some other superior methods. I tried to use Bagging, because of some problems of the package, I could not use XGBClassifier as the base_estimator of Bagging(I don't kown why, but my friend can run my Bagging code in his computer). So, I choosen the ExtraTreesClassifier as my base_estimator. And fortunately, it returned a better result. I decided to reserve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the result is also far from the leader, I tried Stacking. The predictions of (ExtraTreesClassifier, SVM, KNN, XGBC) could be the features and I combined these predictions with X as new features, and I use the Bagging to fit them. The last three methods, they all have distancies of error rate between 2-fold. But this mothod make it more similary. Finally, I got about 0.04 of error rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.n_components = 40\n",
    "        self.n_estimators = 300\n",
    "        self.clf1 = Pipeline([\n",
    "            ('pca', PCA(n_components=self.n_components)),\n",
    "  \n",
    "            ('clf', RandomForestClassifier(n_estimators=self.n_estimators, random_state=42)),\n",
    "            ('XGB', XGBClassifier(max_depth=5, n_estimators=500, learning_rate=0.05,nthread = 1))\n",
    "        ])\n",
    "        self.clf2 = Pipeline([\n",
    "                ('pca', PCA(n_components=self.n_components)),\n",
    "                ('et',ExtraTreesClassifier(n_jobs=4, n_estimators=2000, max_features=20, min_samples_split=3,\n",
    "bootstrap=False, verbose=0, random_state=23))\n",
    "            ])\n",
    "        self.clf3 = Pipeline([\n",
    "                ('pca', PCA(n_components=self.n_components)),\n",
    "                ('svm', SVC(probability=True,C = 1e7))\n",
    "            ])\n",
    "        self.clf4 = Pipeline([\n",
    "                ('pca', PCA(n_components=self.n_components)),\n",
    "                ('bag', BaggingClassifier(base_estimator=self.clf2, n_estimators=5,\n",
    "                                     max_samples=1.,random_state=23))\n",
    "            ]) \n",
    "        self.clf5 = Pipeline([\n",
    "                ('pca', PCA(n_components=self.n_components)),\n",
    "                ('KNN', KNeighborsClassifier(6))\n",
    "            ]) \n",
    "    def fit(self, X, y):\n",
    "        self.clf1.fit(X, y)\n",
    "        self.clf2.fit(X, y)\n",
    "        self.clf3.fit(X,y)\n",
    "        self.clf5.fit(X,y)\n",
    "        #fit 4 classifiers and calulate the prediction based on X\n",
    "        proba1 = self.clf1.predict_proba(X)\n",
    "        proba2 = self.clf2.predict_proba(X)\n",
    "        proba3 = self.clf3.predict_proba(X)\n",
    "        proba5 = self.clf5.predict_proba(X)\n",
    "        # Combination of the predictions and X as the new features\n",
    "        proba = np.concatenate((proba1,proba2,proba3,proba5,X),axis = 1)\n",
    "        #fit them with bagging\n",
    "        self.clf4.fit(proba,y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.clf4.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        #the same operations for x_predict\n",
    "        proba1 = self.clf1.predict_proba(X)\n",
    "        proba2 = self.clf2.predict_proba(X)\n",
    "        proba3 = self.clf3.predict_proba(X)\n",
    "        proba5 = self.clf5.predict_proba(X)\n",
    "        proba = np.concatenate((proba1,proba2,proba3,proba5,X),axis = 1)\n",
    "        return self.clf4.predict_proba(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error = 0.035\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A       0.97      0.97      0.97        63\n",
      "          B       1.00      0.91      0.95        45\n",
      "          Q       1.00      1.00      1.00        40\n",
      "          R       0.91      0.98      0.94        52\n",
      "\n",
      "avg / total       0.97      0.96      0.97       200\n",
      "\n",
      "confusion matrix:\n",
      " [[61  0  0  2]\n",
      " [ 1 41  0  3]\n",
      " [ 0  0 40  0]\n",
      " [ 1  0  0 51]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error = 0.05\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A       0.91      1.00      0.95        49\n",
      "          B       0.98      0.89      0.93        56\n",
      "          Q       1.00      0.96      0.98        47\n",
      "          R       0.92      0.96      0.94        48\n",
      "\n",
      "avg / total       0.95      0.95      0.95       200\n",
      "\n",
      "confusion matrix:\n",
      " [[49  0  0  0]\n",
      " [ 3 50  0  3]\n",
      " [ 1  0 45  1]\n",
      " [ 1  1  0 46]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "labels = np.array(['A', 'B', 'Q', 'R'])\n",
    "\n",
    "def train_test_model_clf(X_df, y_df, skf_is, FeatureExtractor, Classifier):\n",
    "    train_is, test_is = skf_is\n",
    "    X_train_df = X_df.iloc[train_is].copy()                                  \n",
    "    y_train_df = y_df.iloc[train_is].copy()\n",
    "    y_train_clf = y_train_df['molecule'].values\n",
    "    X_test_df = X_df.iloc[test_is].copy()                                    \n",
    "    y_test_df = y_df.iloc[test_is].copy() \n",
    "    y_test_clf = y_test_df['molecule'].values \n",
    "    # Feature extraction\n",
    "    fe_clf = FeatureExtractor()\n",
    "    fe_clf.fit(X_train_df, y_train_clf)\n",
    "    X_train_array_clf = fe_clf.transform(X_train_df)\n",
    "    X_test_array_clf = fe_clf.transform(X_test_df)\n",
    "    # Train\n",
    "    clf = Classifier()\n",
    "    clf.fit(X_train_array_clf, y_train_clf)\n",
    "    # Test \n",
    "    y_proba_clf = clf.predict_proba(X_test_array_clf)                        \n",
    "    y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]                      \n",
    "    error = 1 - accuracy_score(y_test_clf, y_pred_clf)                       \n",
    "    print('error = %s' % error)                                                                            \n",
    "    print('classification report:\\n %s' % classification_report(y_test_clf, y_pred_clf))\n",
    "    print('confusion matrix:\\n %s' % confusion_matrix(y_test_clf, y_pred_clf))\n",
    "\n",
    "\n",
    "skf = ShuffleSplit(n_splits=2, test_size=0.2, random_state=57)  \n",
    "for i in range(2):\n",
    "    skf_is = list(skf.split(X_df))[i]\n",
    "    train_test_model_clf(X_df, y_df, skf_is, FeatureExtractorClf, Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor for regression\n",
    "\n",
    "For this part, I tried to do some feature ingeneering, but most of them change nothing. For example, I tried to use the preprocessing.normalize(), but it was worse than the original method. But in the original method, all values minus the median. I think that all values minus the mean will be more meaningful. So I changed the median to mean. It returned a better result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, I tried to do the normalization for different molecules, but I have no enough time to do it. I think it could be improve the performance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "labels = np.array(['A', 'B', 'Q', 'R'])\n",
    "\n",
    "class FeatureExtractorReg():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y):\n",
    "        pass\n",
    "    #change midian by mean\n",
    "    def transform(self, X_df):\n",
    "        XX = np.array([np.array(dd) for dd in X_df['spectra']])\n",
    "        XX -= np.mean(XX, axis=1)[:, None]\n",
    "        XX /= np.sqrt(np.sum(XX ** 2, axis=1))[:, None]\n",
    "        XX = np.concatenate([XX, X_df[labels].values], axis=1)\n",
    "        return XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression: predicting the concentration\n",
    "\n",
    "\n",
    "\n",
    "As mentionned above, the error metric is the mean absolute relative error (mare): $$\\frac{1}{n_{samples}}\\sum_{k=1}^{n_{samples}}\\left|\\frac{y-\\hat{y}}{y}\\right|$$ with $y$ and $\\hat{y}$ being the true and predicted concentration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part, I made progresses as last cas. I tried several methods of regression, but most of them did not improve the performance, so I tried to merge some methods and give them weights. It really improves the performance(from 0.18 to 0.15). But it did not change much. So, I reused the method of Bagging and Stacking.\n",
    "After Bagging with XGBRegressor, it improved the performance to 0.13. And stacking, I combined the X and the predictions of (XGBRegressor,ExtraTreesRegressor), and inputed them as new features, and train them by Bagging(Base_estimators = XGBRegressor). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it returned the best result, less than 0.1, but actually, it always returned 0.85 or 0.9 in my machine, but it got the mare = 0.1 online. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "class Regressor(BaseEstimator):                                                 \n",
    "    def __init__(self):                                                         \n",
    "        self.n_components = 8                                                 \n",
    "        self.n_estimators = 40                                                  \n",
    "        self.learning_rate = 0.2                                                \n",
    "        self.list_molecule = ['A', 'B', 'Q', 'R']                               \n",
    "        self.dict_reg0 = {}\n",
    "        self.dict_reg1 = {}\n",
    "        self.dict_reg2 = {}\n",
    "        self.dict_reg3 = {}\n",
    "        self.dict_reg4 = {}\n",
    "        for mol in self.list_molecule:                                          \n",
    "            self.dict_reg0[mol] = Pipeline([                                     \n",
    "                ('pca', PCA(n_components=self.n_components)),                   \n",
    "                ('reg', GradientBoostingRegressor(max_depth=5,                              \n",
    "                    n_estimators=self.n_estimators,                             \n",
    "                    learning_rate=self.learning_rate,                           \n",
    "                    random_state=42))                                           \n",
    "            ])\n",
    "           \n",
    "            self.dict_reg1[mol] = Pipeline([                                     \n",
    "                ('pca', PCA(n_components=8)),                   \n",
    "                    ('reg', XGBRegressor(max_depth=4,                              \n",
    "                    n_estimators=300,                             \n",
    "                    learning_rate=self.learning_rate,nthread = 1))                                           \n",
    "            ])\n",
    "            self.dict_reg2[mol] = Pipeline([                                     \n",
    "                ('pca', PCA(n_components=8)),                   \n",
    "                ('reg', XGBRegressor(max_depth=5,n_estimators=300))                                         \n",
    "            ])\n",
    "            self.dict_reg3[mol] = Pipeline([                                     \n",
    "                ('pca', PCA(n_components=8)),                   \n",
    "                    ('reg', ExtraTreesRegressor(max_depth=8,n_estimators=300))                                         \n",
    "            ])\n",
    "            self.dict_reg4[mol] = Pipeline([                                     \n",
    "                ('pca', PCA(n_components=8)),                   \n",
    "               ('bag', BaggingRegressor(base_estimator=self.dict_reg2[mol], n_estimators=20,\n",
    "                                     max_samples=1.,random_state=23))                                       \n",
    "           \n",
    "                ])\n",
    "           \n",
    "                                                                                \n",
    "    def fit(self, X, y):  \n",
    "        for i, mol in enumerate(self.list_molecule):                            \n",
    "            ind_mol = np.where(np.argmax(X[:, -4:], axis=1) == i)[0]            \n",
    "            XX_mol = X[ind_mol]                                                 \n",
    "            y_mol = y[ind_mol].astype(float) \n",
    "            self.dict_reg3[mol].fit(XX_mol, np.log(y_mol))                       \n",
    "            self.dict_reg2[mol].fit(XX_mol, np.log(y_mol))\n",
    "            self.dict_reg4[mol].fit(XX_mol, np.log(y_mol))\n",
    "            y2 = np.exp(self.dict_reg2[mol].predict(XX_mol))\n",
    "            y2 = np.reshape(y2,(len(y2),1))\n",
    "            y3 = np.exp(self.dict_reg3[mol].predict(XX_mol))\n",
    "            y3 = np.reshape(y3,(len(y3),1))\n",
    "            y_new = np.concatenate((XX_mol,y2,y3),axis=1)\n",
    "            self.dict_reg4[mol].fit(y_new,np.log(y_mol))\n",
    "    def predict(self, X):                                                       \n",
    "        y_pred0 = np.zeros(X.shape[0])\n",
    "        y_pred1 = np.zeros(X.shape[0])\n",
    "        y_pred2 = np.zeros(X.shape[0])\n",
    "        y_pred3 = np.zeros(X.shape[0])\n",
    "        y_pred4 = np.zeros(X.shape[0])\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for i, mol in enumerate(self.list_molecule):                            \n",
    "            ind_mol = np.where(np.argmax(X[:, -4:], axis=1) == i)[0]            \n",
    "            XX_mol = X[ind_mol].astype(float)\n",
    "            y2 = np.exp(self.dict_reg2[mol].predict(XX_mol))\n",
    "            y2 = np.reshape(y2,(len(y2),1))\n",
    "            y3 = np.exp(self.dict_reg3[mol].predict(XX_mol))\n",
    "            y3 = np.reshape(y3,(len(y3),1))\n",
    "            y_new = np.concatenate((XX_mol,y2,y3),axis=1)\n",
    "            y_pred4[ind_mol] = np.exp(self.dict_reg4[mol].predict(y_new))\n",
    "        return y_pred4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('error = ', 0.035000000000000031)\n",
      "('mare = ', 0.084206927888730979)\n",
      "('combined error = ', 0.051402309296243676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/zz/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('error = ', 0.050000000000000044)\n",
      "('mare = ', 0.085333650386798188)\n",
      "('combined error = ', 0.061777883462266092)\n"
     ]
    }
   ],
   "source": [
    "def mare_score(y_true, y_pred):                                                  \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) \n",
    "\n",
    "def train_test_model(X_df, y_df, skf_is, FeatureExtractorClf, Classifier, FeatureExtractorReg, Regressor):\n",
    "    train_is, test_is = skf_is\n",
    "    X_train_df = X_df.iloc[train_is].copy()                                  \n",
    "    y_train_df = y_df.iloc[train_is].copy()                                  \n",
    "    X_test_df = X_df.iloc[test_is].copy()                                    \n",
    "    y_test_df = y_df.iloc[test_is].copy()                                    \n",
    "    y_train_clf = y_train_df['molecule'].values                              \n",
    "    y_train_reg = y_train_df['concentration'].values                         \n",
    "    y_test_clf = y_test_df['molecule'].values                                \n",
    "    y_test_reg = y_test_df['concentration'].values                           \n",
    "\n",
    "    # Classification\n",
    "    fe_clf = FeatureExtractorClf()                     \n",
    "    fe_clf.fit(X_train_df, y_train_clf)                                       \n",
    "    X_train_array_clf = fe_clf.transform(X_train_df)                         \n",
    "    X_test_array_clf = fe_clf.transform(X_test_df)                           \n",
    "                                                                                 \n",
    "    clf = Classifier()                                            \n",
    "    clf.fit(X_train_array_clf, y_train_clf)                                  \n",
    "    y_proba_clf = clf.predict_proba(X_test_array_clf)                        \n",
    "    y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]                      \n",
    "    error = 1 - accuracy_score(y_test_clf, y_pred_clf)                       \n",
    "    print('error = ', error)\n",
    "    \n",
    "    # Regression\n",
    "    fe_reg = FeatureExtractorReg()                     \n",
    "    for i, label in enumerate(labels):\n",
    "        # For training, we use \n",
    "        X_train_df.loc[:, label] = (y_train_df['molecule'] == label)         \n",
    "        X_test_df.loc[:, label] = y_proba_clf[:, i]                          \n",
    "    fe_reg.fit(X_train_df, y_train_reg)                                      \n",
    "    X_train_array_reg = fe_reg.transform(X_train_df)                         \n",
    "    X_test_array_reg = fe_reg.transform(X_test_df)                           \n",
    "                                                                                 \n",
    "    reg = Regressor()                                              \n",
    "    reg.fit(X_train_array_reg, y_train_reg)                               \n",
    "    y_pred_reg = reg.predict(X_test_array_reg)\n",
    "    mare = mare_score(y_test_reg, y_pred_reg)\n",
    "    print('mare = ', mare)                \n",
    "    print('combined error = ', 2. / 3 * error + 1. / 3 * mare)\n",
    "\n",
    "\n",
    "skf = ShuffleSplit(n_splits=2, test_size=0.2, random_state=57) \n",
    "for i in range(2):\n",
    "    skf_is = list(skf.split(X_df))[i]\n",
    "\n",
    "    train_test_model(X_df, y_df, skf_is, FeatureExtractorClf, Classifier, FeatureExtractorReg, Regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion\n",
    "\n",
    "1. Maybe I do not find a efficient way to resolve this problem. Because I find the others take less time to train the model. I think that I should search some more effcient methods.\n",
    "\n",
    "2. I should take more attention to the feature ingineering and preprocessiong. It maybe improves the performace.\n",
    "\n",
    "3. I should spend more time to familiar the method in maching learning, because in this challenge, I spended most of time to find convinient method.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I ran my code by python as follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'user_test_submission.py': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!python user_test_submission.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
